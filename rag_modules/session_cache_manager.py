"""
ä¼šè¯ç¼“å­˜ç®¡ç†æ¨¡å—
è´Ÿè´£ç®¡ç†ä¼šè¯çº§è¯­ä¹‰ç¼“å­˜å’Œä¸Šä¸‹æ–‡
"""

import logging
import numpy as np
from typing import Dict, List, Optional, Any
from datetime import datetime

logger = logging.getLogger(__name__)

class SessionCacheManager:
    """
    ä¼šè¯çº§ç¼“å­˜ç®¡ç†å™¨
    
    åŠŸèƒ½ï¼š
    1. ä¼šè¯çº§è¯­ä¹‰ç¼“å­˜ - æ¯ä¸ªèŠå¤©çª—å£ç‹¬ç«‹ç¼“å­˜
    2. ä¸Šä¸‹æ–‡ç®¡ç† - ç»´æŠ¤å¯¹è¯å†å²
    3. è¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é… - æ™ºèƒ½ç¼“å­˜å‘½ä¸­
    """
    
    def __init__(self, embedding_model=None):
        """åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨"""
        self.embedding_model = embedding_model
        
        # ğŸš€ ä¼šè¯çº§è¯­ä¹‰ç¼“å­˜ç³»ç»Ÿ - é’ˆå¯¹æ¯ä¸ªèŠå¤©çª—å£ç‹¬ç«‹ç¼“å­˜
        self.session_caches = {}  # æŒ‰session_idåˆ†ç»„çš„ç¼“å­˜ï¼š{session_id: {query: response}}
        self.session_embeddings = {}  # æŒ‰session_idåˆ†ç»„çš„å‘é‡ï¼š{session_id: {query: embedding}}
        self.session_contexts = {}  # æŒ‰session_idåˆ†ç»„çš„ä¸Šä¸‹æ–‡ï¼š{session_id: [messages]}
        
        # ç¼“å­˜é…ç½®
        self.cache_threshold = 0.75  # è¯­ä¹‰ç›¸ä¼¼åº¦é˜ˆå€¼
        self.max_session_cache_size = 50  # æ¯ä¸ªä¼šè¯æœ€å¤§ç¼“å­˜æ¡ç›®æ•°
        self.max_context_length = 10  # æ¯ä¸ªä¼šè¯ä¿ç•™çš„æœ€å¤§ä¸Šä¸‹æ–‡æ¶ˆæ¯æ•°
    
    def _calculate_similarity(self, embedding1: np.ndarray, embedding2: np.ndarray) -> float:
        """è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦"""
        try:
            dot_product = np.dot(embedding1, embedding2)
            norm1 = np.linalg.norm(embedding1)
            norm2 = np.linalg.norm(embedding2)
            return dot_product / (norm1 * norm2)
        except:
            return 0.0

    def check_semantic_cache(self, query: str, session_id: str = None) -> Optional[str]:
        """æ£€æŸ¥ä¼šè¯çº§è¯­ä¹‰ç¼“å­˜ä¸­æ˜¯å¦æœ‰ç›¸ä¼¼æŸ¥è¯¢"""
        if not session_id or session_id not in self.session_caches:
            return None

        session_cache = self.session_caches[session_id]
        session_embeddings = self.session_embeddings[session_id]

        if not session_cache:
            return None

        try:
            # è®¡ç®—æŸ¥è¯¢å‘é‡
            query_embedding = self.embedding_model.embed_documents([query])[0]
        except Exception as e:
            logger.warning(f"æŸ¥è¯¢å‘é‡è®¡ç®—å¤±è´¥: {e}")
            return None

        # æŸ¥æ‰¾æœ€ç›¸ä¼¼çš„ç¼“å­˜æŸ¥è¯¢
        best_similarity = 0
        best_response = None

        for cached_query, cached_data in session_cache.items():
            cached_embedding = session_embeddings.get(cached_query)
            if cached_embedding is not None:
                similarity = self._calculate_similarity(query_embedding, cached_embedding)
                if similarity > best_similarity and similarity >= self.cache_threshold:
                    best_similarity = similarity
                    best_response = cached_data['response']

        if best_response:
            logger.info(f"ğŸ¯ ä¼šè¯ç¼“å­˜å‘½ä¸­! Session: {session_id}, ç›¸ä¼¼åº¦: {best_similarity:.3f}")
            return best_response

        return None

    def add_to_semantic_cache(self, query: str, response: str, session_id: str = None):
        """å°†æŸ¥è¯¢-ç­”æ¡ˆå¯¹æ·»åŠ åˆ°ä¼šè¯çº§è¯­ä¹‰ç¼“å­˜"""
        try:
            if not session_id:
                return

            # åˆå§‹åŒ–ä¼šè¯ç¼“å­˜
            if session_id not in self.session_caches:
                self.session_caches[session_id] = {}
                self.session_embeddings[session_id] = {}

            session_cache = self.session_caches[session_id]
            session_embeddings = self.session_embeddings[session_id]

            # é™åˆ¶ä¼šè¯ç¼“å­˜å¤§å°
            if len(session_cache) >= self.max_session_cache_size:
                # åˆ é™¤æœ€æ—§çš„ç¼“å­˜é¡¹
                oldest_key = next(iter(session_cache))
                del session_cache[oldest_key]
                del session_embeddings[oldest_key]

            # è®¡ç®—æŸ¥è¯¢å‘é‡
            query_embedding = self.embedding_model.embed_documents([query])[0]

            # æ·»åŠ åˆ°ç¼“å­˜
            session_cache[query] = {
                'response': response,
                'timestamp': datetime.now().isoformat()
            }
            session_embeddings[query] = query_embedding

            logger.info(f"ğŸ“ å·²æ·»åŠ åˆ°ä¼šè¯ç¼“å­˜ {session_id}, å½“å‰å¤§å°: {len(session_cache)}")

        except Exception as e:
            logger.warning(f"æ·»åŠ åˆ°è¯­ä¹‰ç¼“å­˜å¤±è´¥: {e}")

    def add_to_context(self, session_id: str, query: str, response: str):
        """æ·»åŠ å¯¹è¯åˆ°ä¸Šä¸‹æ–‡å†å²"""
        try:
            if not session_id:
                return

            # åˆå§‹åŒ–ä¼šè¯ä¸Šä¸‹æ–‡
            if session_id not in self.session_contexts:
                self.session_contexts[session_id] = []

            context = self.session_contexts[session_id]

            # æ·»åŠ æ–°çš„å¯¹è¯
            context.append({
                'query': query,
                'response': response,
                'timestamp': datetime.now().isoformat()
            })

            # é™åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦
            if len(context) > self.max_context_length:
                context.pop(0)  # åˆ é™¤æœ€æ—§çš„å¯¹è¯

            logger.info(f"ğŸ“ å·²æ·»åŠ ä¸Šä¸‹æ–‡åˆ°ä¼šè¯ {session_id}, å½“å‰é•¿åº¦: {len(context)}")

        except Exception as e:
            logger.warning(f"æ·»åŠ ä¸Šä¸‹æ–‡å¤±è´¥: {e}")

    def get_context_for_query(self, session_id: str, current_query: str) -> str:
        """è·å–å¢å¼ºçš„æŸ¥è¯¢ä¸Šä¸‹æ–‡"""
        try:
            if not session_id or session_id not in self.session_contexts:
                return current_query

            context = self.session_contexts[session_id]
            if not context:
                return current_query

            # æ„å»ºä¸Šä¸‹æ–‡å¢å¼ºçš„æŸ¥è¯¢
            context_parts = []
            
            # æ·»åŠ æœ€è¿‘çš„å¯¹è¯å†å²ï¼ˆæœ€å¤š3è½®ï¼‰
            recent_context = context[-3:] if len(context) > 3 else context
            
            for item in recent_context:
                context_parts.append(f"ç”¨æˆ·é—®: {item['query']}")
                context_parts.append(f"AIç­”: {item['response'][:100]}...")  # æˆªå–å‰100å­—ç¬¦
            
            # æ·»åŠ å½“å‰æŸ¥è¯¢
            context_parts.append(f"å½“å‰é—®é¢˜: {current_query}")
            
            enhanced_query = "\n".join(context_parts)
            
            logger.info(f"ğŸ”— å·²ä¸ºä¼šè¯ {session_id} æ„å»ºä¸Šä¸‹æ–‡å¢å¼ºæŸ¥è¯¢")
            return enhanced_query

        except Exception as e:
            logger.warning(f"ä¸Šä¸‹æ–‡è·å–å¤±è´¥: {e}")
            return current_query

    def get_session_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'total_sessions': len(self.session_caches),
            'total_cached_queries': sum(len(cache) for cache in self.session_caches.values()),
            'total_contexts': sum(len(context) for context in self.session_contexts.values()),
            'cache_threshold': self.cache_threshold,
            'max_session_cache_size': self.max_session_cache_size,
            'max_context_length': self.max_context_length
        }

    def clear_session_cache(self, session_id: str):
        """æ¸…é™¤æŒ‡å®šä¼šè¯çš„ç¼“å­˜"""
        if session_id in self.session_caches:
            del self.session_caches[session_id]
        if session_id in self.session_embeddings:
            del self.session_embeddings[session_id]
        if session_id in self.session_contexts:
            del self.session_contexts[session_id]
        logger.info(f"ğŸ—‘ï¸ å·²æ¸…é™¤ä¼šè¯ {session_id} çš„ç¼“å­˜")

    def clear_all_caches(self):
        """æ¸…é™¤æ‰€æœ‰ç¼“å­˜"""
        self.session_caches.clear()
        self.session_embeddings.clear()
        self.session_contexts.clear()
        logger.info("ğŸ—‘ï¸ å·²æ¸…é™¤æ‰€æœ‰ä¼šè¯ç¼“å­˜")
